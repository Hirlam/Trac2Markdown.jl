[[PageOutline]]

= Practicals =
 * Binaries: cca:/perm/ms/spsehlam/hlam/daTraining/bin_cy43h2
 * Data: cca:/perm/ms/spsehlam/hlam/daTraining/data or ecgate:/hpc/perm/ms/spsehlam/hlam/daTraining/data

== Environment ==

'''Every time you log in to ecgate''':
{{{
#
# on ecgate: add DA Training PATH, environment variables and modules
#
. /home/ms/spsehlam/hlam/daTraining/user_env.sh
}}}

== ECMWF Quotas ==
Check your EMWF disk quotas (https://confluence.ecmwf.int/display/UDOC/File+systems) with the following:
 * ecgate ($HOME, $PERM, $SCRATCH)
{{{
ecquota
}}}
 * cca/ccb ($HOME, $PERM, $SCRATCH -- [https://confluence.ecmwf.int/display/UDOC/HPCF+user+filesystems https://confluence.ecmwf.int/display/UDOC/HPCF+user+filesystems])
{{{
quota -s
}}}

You may wish to run some experiments in $SCRATCH (transient) instead of $PERM (permanent).

== Default ecFlow Server settings ==
 * Name: your userid:
{{{
whoami
}}}
 * Host: ecgb11
 * Port: uid+1500
{{{
expr `id -u $USER` + 1500
}}}

== Day 1 ==
=== BUFR Observations ===
Reference material:
 * [https://confluence.ecmwf.int/display/ECC/ ecCodes]
 * [http://www.wmo.int/pages/prog/www/ois/Operational_Information/Publications/WMO_386/AHLsymbols/AHLsymbols_en.html GTS headers]
   * [http://www.wmo.int/pages/prog/www/ois/Operational_Information/Publications/WMO_386/AHLsymbols/TableA.html T1 for T1T2A1A2ii definitions]
   * [http://www.wmo.int/pages/prog/www/ois/Operational_Information/VolumeC1/CCCC_en.pdf CCCC location indicators]
 * [https://confluence.ecmwf.int/display/ECC/BUFR+headers BUFR headers] (ecCodes)
 * [https://apps.ecmwf.int/odbgov/bufrtype/ ECMWF BUFR data categories]
 * [https://apps.ecmwf.int/odbgov/bufrtype/ ECMWF BUFR local data sub-categories]
 * [http://www.wmo.int/pages/prog/www/WMOCodes/WMO306_vI2/LatestVERSION/WMO306_vI2_CommonTable_en.pdf WMO BUFR data categories] (Code table C-13)

'''Practical: [raw-attachment:eoinWhelan_Obs_Practical_NoSolutions.pdf:wiki:HarmonieSystemDocumentation/Training/HarmonieSystemTraining2019 BUFR Observations]'''

'''Plotting:'''
{{{
. /home/ms/spsehlam/hlam/daTraining/user_env.sh
plotWmoObsConv -h       ## Plot WMO conventional BUFR
plotEcmObsConv -h       ## Plot ECMWF conventional BUFR
plotEumObsConv -h       ## Plot EUMETSAT satellite BUFR
plotOdbStatus  -h       ## Plot ODB status (report_status|datum_status)
plotOdbVals    -h       ## Plot ODB values (obsvalue|fg_depar|an_depar)
}}}

=== Bator and ODB ===
Reference material:
 * [https://apps.ecmwf.int/odbgov ECMWF ODB governance database]
 * [https://confluence.ecmwf.int/display/ODBAPI ODB]: ECMWF documentation and software
 * [http://www.umr-cnrm.fr/aladin/meshtml/DOC_odb/odb.php ODB (MF)]: List of useful links provided by Météo France
 * [http://www.umr-cnrm.fr/gmapdoc/spip.php?rubrique33 GmapDoc: Observations]: ARPEGE/ALADIN/AROME (Météo France) documentation

'''Practical:'''
 * Produce some ODBs from ECMWF BUFR
{{{
#
#    BUFR --> ODB suite
#    Can cycle for 2018081900 --> 2018081921
#    One cycle uses about 720 MB in $PERM on cca
#
# on ecgate
#
. /home/ms/spsehlam/hlam/daTraining/user_env.sh
mkdir -p $HOME/hm_home/daBufr2odb
cd $HOME/hm_home/daBufr2odb
HarmonieDA setup
#sed -i 's/\.perm\./.scratch./g' config-sh/config.ecgb-cca # Use $SCRATCH instead of $PERM
HarmonieDA start DTG=2018081900 PLAYFILE=bufr2odb
}}}

 * Produce ODBs from (OBSOUL and GTS BUFR) with stand-alone BATOR
{{{
#
# on cca/ccb
#
cd $PERM
tar xvf /perm/ms/spsehlam/hlam/daTraining/Day_1/sample_bator.tar
# follow exercises & guidelines
vi sample_bator/README

}}}


== Day 2 ==
 * More about the exercises can be found [https://hirlam.org/trac/attachment/wiki/HarmonieSystemDocumentation/Training/HarmonieSystemTraining2019/Screening_Monitoring_exercises.pdf  here]
 * Run Screening only
{{{
#
#    Screening suite
#    Can cycle for 2018081900 --> 2018081921
#    One cycle uses about 1.5 G B in $PERM on cca
#
# on ecgate
#
. /home/ms/spsehlam/hlam/daTraining/user_env.sh
mkdir -p $HOME/hm_home/daScreening
cd $HOME/hm_home/daScreening
HarmonieDA setup
#sed -i 's/\.perm\./.scratch./g' config-sh/config.ecgb-cca # Use $SCRATCH instead of $PERM
HarmonieDA start DTG=2018081900 PLAYFILE=screening
}}}

 * Obsmon
{{{

# on cca/ccb
mkdir $TEMP/training
cd $TEMP/training
qsub /perm/ms/no/sbu/training/exercises/obsmon_training.job

# Results end up in $TEMP/training/obsmon/archive

# Visualize ODB with Shiny

# Extra
# Make a local copy of:
# /perm/ms/no/sbu/training/exercises/obsmon_training.job
# /perm/ms/no/sbu/training/exercises/include.ass-training

cp /perm/ms/no/sbu/training/exercises/obsmon_training.job  $TEMP/training/.
cp /perm/ms/no/sbu/training/exercises/include.ass-training $TEMP/training/.

# Modifiy the variable config in $TEMP/training/obsmon_training.job to $TEMP/training/include.ass-training

# Modify $TEMP/training/include.ass-training to only monitor e.g. AIRCRAFT

# Move $TEMP/training/obsmon/ if you want to keep it
mv $TEMP/training/obsmon $TEMP/training/obsmon-orig

# Submit modified job script
qsub $TEMP/training/obsmon_training.job


}}}

 * Local installation of obsmon
{{{
1. Get obsmon from hirlam.org:

  git clone https://git.hirlam.org/Obsmon obsmon

2. Install obsmon:

  cd obsmon

  ./install --local-install

3. Set up a valid config.toml file.
  This file tells obsmon where to find the experiments. Please take a look at
  the example file "config.toml.example" included with obsmon.

4. Finally, run obsmon:

  ./obsmon --launch
}}}

== Day 3 ==

  * Reminder '''Every time you log in to ecgate''':
{{{
#
# on ecgate: add DA Training PATH, environment variables and modules
#
. /home/ms/spsehlam/hlam/daTraining/user_env.sh
}}}


 * Run Screening plus 3D-Var minimization single obs experiment (TEMP radiosonde observation at 500 hPa 1K warmer than the background)
{{{
#
#    Minim suite
#    Can cycle for 2018081900 --> 2018081921
#    One cycle uses about 2.8 GB in $PERM on cca
#
# on ecgate
#
. /home/ms/spsehlam/hlam/daTraining/user_env.sh
mkdir -p $HOME/hm_home/daSingleObs
cd $HOME/hm_home/daSingleObs
HarmonieDA setup
#sed -i 's/\.perm\./.scratch./g' config-sh/config.ecgb-cca # Use $SCRATCH instead of $PERM
sed -i 's/USEOBSOUL=0/USEOBSOUL=1/g' scr/include.ass
sed -i 's/SINGLEOBS=no/SINGLEOBS=yes/g' sms/config_exp.h
HarmonieDA start DTG=2018081900 PLAYFILE=singleobs
}}}

 * Run Screening plus 3D-Var minimization
{{{
#
#    Minim suite
#    Can cycle for 2018081900 --> 2018081921
#    One cycle uses about 2.8 GB in $PERM on cca
#
# on ecgate
#
. /home/ms/spsehlam/hlam/daTraining/user_env.sh
mkdir -p $HOME/hm_home/daMinim
cd $HOME/hm_home/daMinim
HarmonieDA setup
#sed -i 's/\.perm\./.scratch./g' config-sh/config.ecgb-cca # Use $SCRATCH instead of $PERM
HarmonieDA start DTG=2018081900 PLAYFILE=minim
}}}

== Day 4 ==

 * Run Surface DA (CANARI + SURFEX OI)
{{{
#
#    Surf suite
#    Can cycle for 2018081900 --> 2018081921
#    One cycle uses about 1.9 GB in $PERM on cca
#
# on ecgate
#
. /home/ms/spsehlam/hlam/daTraining/user_env.sh
mkdir -p $HOME/hm_home/daSurf
cd $HOME/hm_home/daSurf
HarmonieDA setup
#sed -i 's/\.perm\./.scratch./g' config-sh/config.ecgb-cca # Use $SCRATCH instead of $PERM
HarmonieDA start DTG=2018081900 PLAYFILE=surf

# Now turn off your screen level and snow analysis. (see presentation)

nam/harmonie_namelists.pm:

NACTEX=>{
'LAET2M' => '.FALSE.,',
'LAEH2M' => '.FALSE.,',
'LAESNM' => '.FALSE.,',

# Re-run your experiment
HarmonieDA start DTG=2018081900 PLAYFILE=surf

}}}

 * Run SODA for TEST_11 DOMAIN with FA files as input
{{{
#
# On cca/ccb
#

mkdir -p $TEMP/training/
cd $TEMP/training/
/perm/ms/no/sbu/training/exercises/prepare_exp.sh TEST_11 FA

# Do modifications if wanted inside $TEMP/training/TEST_11_FA
# Submit batch job
qsub /perm/ms/no/sbu/training/exercises/TEST_11_FA.job

# You will get an outputfile in
$TEMP/training/TEST_11_FA/SURFOUT.fa

# This file should be the input to 3D-VAR/initialization/forecast as ICMCHANAL+0000.sfx

# The standard output is found in $TEMP/training/TEST_11_FA.job.o*
# The output from the IO node is in $TEMP/training/TEST_11_FA/LISTING_SODA0.txt

}}}

* Run SODA for TEST_11 DOMAIN with NetCDF files as input and on several CPUs
{{{
#
# On cca/ccb
#

mkdir -p $TEMP/training/
cd $TEMP/training/
/perm/ms/no/sbu/training/exercises/prepare_exp.sh TEST_11 NC

# Do modifications if wanted inside $TEMP/training/TEST_11_NC
# Submit batch job
cd $TEMP/training/
qsub /perm/ms/no/sbu/training/exercises/TEST_11_NC.job

# You will get an outputfile in
$TEMP/training/TEST_11_NC/SURFOUT.nc

# You will also get NetCDF files for prognostic and diagnostic variables

# This file should be the input to e.g. other offline runs
# These files are convenient for offline runs, but the diagnostic does not 
# make sense for the assimilation (no time step is performed)

# The standard output is found in $TEMP/training/TEST_11_NC.job.o*
# The output from the IO node is in $TEMP/training/TEST_11_NC/LISTING_SODA0.txt
# Have a look on increments in: $TEMP/training/TEST_11_NC/LISTING_SODA0.txt

#
# Calculate increments from the files:
#
# Load modules (if needed)
module load nco
module load ncview

# Enter working directory
cd $TEMP/training/TEST_11_NC

# Calculate difference with nco
ncdiff -O SURFOUT.nc PREP.nc ANINC.nc

# Look at the increments 
ncview ANINC.nc 


############# START OF NEW EXP #########################
# Now let us play with some settings
# First take a copy of your previous experiment. Here it is called TEST_11_NC-MY-PREVIOUS-EXP-DESCRIPTION

mv $TEMP/training/TEST_11_NC $TEMP/training/TEST_11_NC-MY-PREVIOUS-EXP-DESCRIPTION

# Re-do the above steps as listed here:
#
cd $TEMP/training/
/perm/ms/no/sbu/training/exercises/prepare_exp.sh TEST_11 NC

# Do modifications inside $TEMP/training/TEST_11_NC
# See exercises below. Modify OPTIONS.nam !!!!

# Submit batch job
cd $TEMP/training/
qsub /perm/ms/no/sbu/training/exercises/TEST_11_NC.job

# The standard output is found in $TEMP/training/TEST_11_NC.job.o*
# The output from the IO node is in $TEMP/training/TEST_11_NC/LISTING_SODA0.txt

#
# Calculate increments from the files:
#
# Load modules (if needed)
module load nco
module load ncview

# Enter working directory
cd $TEMP/training/TEST_11_NC

# Calculate difference with nco
ncdiff -O SURFOUT.nc PREP.nc ANINC.nc

# Look at the increments 
ncview ANINC.nc 

# Compare the experiments

######### END OF NEW EXP ################

Exercise 1)

Turn off all observation increments
&NAM_OBS
....
  NOBSTYPE  = 0,
  NNCO      = 0,0,0,0,0
/

Turn off snow update:
&NAM_ASSIM
  LAESNM              = .FALSE.


Did you get any increments for soil moisture and soil temperature? Why, or why not?

Exercise 2)

.......

}}}

== Day 5 ==
 - Instructions and exercises: [https://hirlam.org/trac/attachment/wiki/HarmonieSystemDocumentation/Training/HarmonieSystemTraining2019/diagnostics_in_DA_exercises.pdf Diagnostic tools]

* Diagnosis of spinup (ECHKEVO): exercise 1
{{{
  on cca: cd $SCRATCH or $TEMP
  cp /perm/ms/spsehlam/hlam/daTraining/Day_5/sample_echkevo .
}}}

* Perturbation of observations and Degrees of Freedom for Signal (DFS): exercises 2-4
{{{
  on cca: cd $SCRATCH or $TEMP
  cp /perm/ms/spsehlam/hlam/daTraining/Day_5/sample_dfs .
}}}

* Diagnosis of B and R using Obstool: exercise 5
{{{
  on cca: cd $SCRATCH or $TEMP
  cp /perm/ms/spsehlam/hlam/daTraining/Day_5/sample_obstool .
}}}












