[[PageOutline]]

[[Center(begin)]]
== '''Hirlam System Documentation''' ==
= Verification Statistics =
[[Center(end)]]

[[Center(begin)]]
== '''Overview''' ==
[[Center(end)]]

 1. At the the moment the Hirlam reference system produces verification statics for every cycle. The forecasts are compared to observations (obs verification) and analysis (field verification).

 1. Verification statistics over a given time can be obtained by running a separate run. However, at the moment quite a limited set of verification statistics can be computed and illustrated in a graphical form. A preliminary version of a enhanced package is available and several users have tried and used it. This work is on-going.

[[Center(begin)]]
== '''Implementation, data flow''' ==
[[Center(end)]]

On every cycle all the forecasts valid at that are verified at the same time, because observations and
analysis exists. This requires that all the forecasts valid must be available. In normal case this is 
optimized in such a way that the files needed from previous cycles are not removed before they are verified. 
In practice, the file existence is checked and th file is fetched from the archive, if it does not exist on disk.  So this requires a lot of disk space.

=== '''Observation verification''' ===

All the forecasts valid at the analysis time are analyzed in a loop and an ASCII file is created that contains all the observation verification statistics. The file names are
{{{
'''ve'''yyyymmdd_hh
'''pct'''yyyymmdd_hh
}}}
where yyyy is year mm month, dd day and hh hour. The first file contains rms-error and bias statistics and the latter one the contingency tables for precipitation forecasts. 
The run is controlled by a namelist file verificationSpecs.h specified in the directory scripts. 

In addition a file called 
{{{
OFyyyymmdd_hh.tar.gz
}}}

is created. This file contains data of (near)-surface parameters (station id, coordinates, observed value, forecast value and their difference). 

=== '''Field verification''' ===
In the field verification the initialized analysis is used as truth by default. If that does not exist then analyzed fields are used.
Cumulative files are created on monthly basis separately for every analysis hour  of the forecast. More specifically, the following files are created, for example for September 2006

{{{
cf200609_00+000      ...      cf200609_00+048
cf200609_00+000ve    ...      cf200609_00+048ve
}}}

{{{
ef200609_00+000      ...      ef200609_00+048
ef200609_00+000ve    ...      ef200609_00+048ve
}}}


For example the file cf200609_00+048  contain mean values of 48 hour forecast fields from the forecasts started from 00 UTC analysis, ie. 48 hour forecasts' climate, on model levels, accumulated for September 2006.  ve-files contain the same for constant pressure levels. ef-files contain the rms-error and bias fileds accumulated for the current month. The files contain all the fields that are in the original model-level or contant-pressure
level files. The files are Asimof-files.

[[Center(begin)]]
== '''Relevant code and scripts''' ==
[[Center(end)]]
=== '''Scripts''' ===
The verification is performed in the Postprocessing phase and initiated with '''Verify.sms''', which
calls the perl-script '''Verify.pl'''. Note that this is the main script for verification and 
'''the script Verify is not used at all any more'''.

'''Verify.pl''' controls the run, gets and archives the input/output files and calls the following scripts:
{{{
RainRate             # computes precipitation of shorter periods
Access_lpfs          # get observations from archive
dearchive            # gets field files from archive
Compare              # verification against observations
Fdvrfy               # field verification
}}}

=== '''Code''' ===
The relevant main source programs are the following, only the main programs are listed:
{{{
intp/intp.f          Interpolation of forecast to observation locations
vrfy/comper.f        Observation verification computation
util/vrfy.f          Field verification computations
}}}

=== '''Variables, namelists''' ===
Shell variable '''HL_VER''' (default $HL_EXP) can be defined in Enc_system (must be defined as EXPORT). 
In this case observation are fetched from the archibe '''$HL_VER''' instead of '''$HL_EXP'''. This allows the
user to take verifying observations from some other experiment.

Otherwise the verification is controlled by the namelist {{{VerificationSpecs.h}}}.

This allows the user to define:
 * Define the geographical area for which observations are picked up from the archive file.
 * Define the contingency table specification for the precipitation verification.
 * Define as many areas as the user wants for which the verification statistics are computed.
 * Define the rejection limits for different observed parameters.
 * Define the parameters to be verified
 * Define the levels of sounding data to be verified

Additional notes:
 * The areas are defined separately for surface data (SYNOP) and sounding data (TEMP)
 * The areas can be defined either by defineng the geographical area or giving a list of WMO station numbers
 * The definitions are additive in the sense that the previously defined relevant value is used, if it is not re-defined in the namelist.

In practice, the default namelist is used in most cases.


[[Center(begin)]]
== '''Methodology, verification products''' ==
[[Center(end)]]
In practice all the forecasts valid at the current analysis time are verified in a loop. 
This makes the whole procedure technically heavy:
 * All the forecasts must be on disk, a lot of disk space required
 * If they are not, they are fetched from the archive. So a lot of traffic between archive and local disks are required.


The field verification is a straight forward process: 
 1. Each field in the forecast file is compared against the analysed value gridpoint by gridpoint and the rms-error, bias and mean field values in the output verification file are updated.
 1. The output file is selected accrding the initial time of the forecast. For instance, all the forecasts from 00 UTC run are stored in the same file. In the same way for other daily cycles. See the file naming earlier in this document.

Observation verification needs more comments:
 1. Observations are fetched from the experiment $HL_VER (default own experiment). This allows using the observation file to be used in verifying different experiments.
 1. Because the forecast files contain only accumulated precipitation from the beginning of the forecast, it is necessay to compute first the precipitation amount for 6, 12 and 24 hour periods to be able to compare against observations.
 1. The forecast values are interpolated bi-linearly to the observation points. This is certainly enough for sounding data, but concerning surface values, especially 2meter temperature and 10-meter wind this may not be adquate.
 1. The quality control takes place against to the defined limits (given in {{{VerificationSpec.h}}}):
    * If the observation and forecast differ more the pre-defined limit, the observation is nor used
    * This means that different experiments can use a different data set for verfication even if the observation file is used in verification.
    * This may affect results in one synoptic case, but probably does not have much influence if mean values of verification scores over a longer time period are considered.
 1. Finally the bias, rms-error and std-error over given areas are computed
 1. A observed values and forecast values together with the station identification are collected for all stations and written out as a simple ASCII file. Finally these files are collected together to form the OFyyyymmdd_hh.tar.gz file.
 

[[Center(begin)]]
== '''Verification statistics over a time period''' ==
[[Center(end)]]
After an experiment has been run, it is possible to runa separate run to get verification statistics
in graphical form for the whole time period. In this run it is possible to define several experiments and 
the scores are plotted in the same picture to make the comparison easy.
The graphics are based on gnuplot and Grads, which both free software.

This run is started with
{{{
Hirlam start DTG=yyyymmddhh DTGEND=yyyymmddhh PLAYFILE=verif_summary
}}}

The job is controlled by the env-file '''Env_verif_sum''', where you define the needed parametrs.


{{{
# Specify Verification plots
# Run the package with "Hirlam start DTG=1995070300 DTGEND=1995070306 PLAYFILE=verif_summary"
arc_dir=$HL_ARC			# 1. The actual fields are found in directory $arc_dir/$EXP

wrk_dir=$HL_DATA/$$		# 2. Temporary work directory

out_dir=$HL_DATA/Vrfy_and_Valid	# 3. Output directory, where the results
				# will be written.

VEXPS="$EXP ref"		# 4. Experiments, which will be compared
				# The verification results against
				# observations from every experiment
				# are plotted to same plots

VINI_TIMES="00 06 12 18"	# 5. Initial times of forecasts included
				# in the verfication

VAREAS="all EWG"		# 6. Verifications areas included. Choose from:
				# all EWG Afr Fin FIN Fra IrE NNS Nt+ Scn SNS Spa

VT_INT=3			# 7. Time interval of data assimilation

ARC_DIR=${ARC_DIR-$arc_dir}
WRK_DIR=${WRK_DIR-$wrk_dir}
OUT_DIR=${OUT_DIR-$out_dir}
}}}



A preliminary version of a more extensive verification package is available at ECMWF in ecfs in 
the directory  {{{ec:/fne/Verif_package}}}. Some pioneer users have already used it and accroding to
their comments the package will be modified and improved. The aim is to get it as a part of the reference
system. It is run and controlled in the same way as the ccurrent reference version verification package.
Examples of the products of the new package are given in a separate presentation.

[[Center(begin)]]
== '''Common error messages''' ==
[[Center(end)]]
[[Center(begin)]]
== '''Overhaul issues, questions''' ==
[[Center(end)]]
From the technical point of view the daily system of computing verification statistics is stable.

A few comments of can be made
 * In the field verification system it is at the moment impossible afterwards see, which forecasts are included in statistics, because the files contain only the computed rms-error, bias or mean field. The number of cases can be seen in the GRIB header. A first step could be to implement a separate inventory file, which contains information about the forecasts included.
 * A separate small program could be written, which combines different field verification error files. This could be afterwards to combine error statistics, for instance from 00 and 12 UTC runs, or from different months.

Concerning the enhanced package of presenting verification results, comments have been gathered from the pioneer users and based of this information a plan of new corrections/new features wil made.

[[Center(begin)]]
[https://hirlam.org/trac/wiki/HirlamSystemDocumentation Back to the main page of the HIRLAM-System Documentation]
[[Center(end)]]
----
[[Center(begin)]]
[[Disclaimer]]

